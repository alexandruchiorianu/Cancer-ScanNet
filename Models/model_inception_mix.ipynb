{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Conv2D, Flatten, MaxPooling2D, BatchNormalization, \\\n",
    "SpatialDropout2D, GlobalMaxPooling2D, Input, LeakyReLU, AveragePooling2D, MaxPool2D, Concatenate, Lambda\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "\n",
    "INPUT_FOLDER = 'C:/Users/alexa/___Licenta_v2/dataset/train/'\n",
    "OUTPUT_FOLDER = 'D:/Licenta/new_try_kaggle/cnn_models/'\n",
    "OUTPUT_FOLDER_TB = 'D:/Licenta/new_try_kaggle/cnn_models/tensor_boards/'\n",
    "\n",
    "train_samples = os.listdir(INPUT_FOLDER)\n",
    "train_samples.sort()\n",
    "\n",
    "random.shuffle(train_samples)\n",
    "\n",
    "labels_df = pd.read_csv('D:/Licenta/new_try_kaggle/train_labels.csv', index_col=0)\n",
    "labels_df['label'] = labels_df['label'].astype(object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\conda\\conda\\envs\\licentav2\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer-3838-non_cancer-5582\n",
      "cancer-40487-non_cancer-59513\n"
     ]
    }
   ],
   "source": [
    "partition = dict()\n",
    "all_labels = dict()\n",
    "partition['train'] = train_samples[:100000]\n",
    "partition['validate'] = train_samples[100000:]\n",
    "\n",
    "all_cancer = list()\n",
    "\n",
    "for sample in train_samples:\n",
    "    \n",
    "    label = labels_df.get_value(sample[:-4], 'label')\n",
    "    all_labels[sample] = label\n",
    "      \n",
    "cancer = 0\n",
    "non_cancer = 0\n",
    "for key in partition['validate']:\n",
    "    if all_labels[key] == 1:\n",
    "        cancer+=1\n",
    "    else:\n",
    "        non_cancer+=1\n",
    "        \n",
    "print(f\"cancer-{repr(cancer)}-non_cancer-{repr(non_cancer)}\")\n",
    "cancer = 0\n",
    "non_cancer = 0\n",
    "for key in partition['train']:\n",
    "    if all_labels[key] == 1:\n",
    "        cancer+=1\n",
    "    else:\n",
    "        non_cancer+=1\n",
    "        \n",
    "print(f\"cancer-{repr(cancer)}-non_cancer-{repr(non_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(kernel_size, pool_size, first_filters, second_filters, third_filters, fourth_filters, dropout_conv,dropout_dense):\n",
    "    \n",
    "    #now add layers to it\n",
    "    Input_1 = Input(shape=(32,32,4))\n",
    "    x_rgb = Lambda(lambda Input_1 : Input_1[:,:,:,:3])(Input_1)\n",
    "    print(x_rgb.shape)\n",
    "\n",
    "    x_grey = Lambda(lambda Input_1 : Input_1[:,:,:,3:])(Input_1)\n",
    "    #conv block 1 for the first three channels\n",
    "    first_Convolution2D_1_2 = Conv2D(first_filters, (3,3), use_bias=False)(x_rgb)\n",
    "    \n",
    "    first_BatchNormalization_1_2 = BatchNormalization()(first_Convolution2D_1_2)\n",
    "    first_Activation_1_2 = Activation('relu')(first_BatchNormalization_1_2)\n",
    "    \n",
    "    first_SpatialDroupout2D_1 = SpatialDropout2D(dropout_conv)(first_Activation_1_2)\n",
    "    \n",
    "    #conv block 2 for the first three channels\n",
    "    first_Convolution2D_2_1 = Conv2D(second_filters, kernel_size, use_bias=False)(first_SpatialDroupout2D_1)\n",
    "    first_BatchNormalization_2_1 = BatchNormalization()(first_Convolution2D_2_1)\n",
    "    \n",
    "    first_Activation_2_1 = Activation('relu')(first_BatchNormalization_2_1)\n",
    "    first_Convolution2D_2_2 = Conv2D(second_filters, kernel_size, use_bias=False)(first_Activation_2_1)\n",
    "    \n",
    "    first_BatchNormalization_2_2 = BatchNormalization()(first_Convolution2D_2_2)\n",
    "    first_Activation_2_2 = Activation('relu')(first_BatchNormalization_2_2)\n",
    "    \n",
    "    first_SpatialDroupout2D_2 = SpatialDropout2D(dropout_conv)(first_Activation_2_2)\n",
    "    \n",
    "    #conv block 3 for the first three channels\n",
    "    first_Convolution2D_3_1 = Conv2D(third_filters, kernel_size, use_bias=False)(first_SpatialDroupout2D_2)\n",
    "    first_BatchNormalization_3_1 = BatchNormalization()(first_Convolution2D_3_1)\n",
    "    \n",
    "    first_Activation_3_1 = Activation('relu')(first_BatchNormalization_3_1)\n",
    "    first_Convolution2D_3_2 = Conv2D(third_filters, kernel_size, use_bias=False)(first_Activation_3_1)\n",
    "    \n",
    "    first_BatchNormalization_3_2 = BatchNormalization()(first_Convolution2D_3_2)\n",
    "    first_Activation_3_2 = Activation('relu')(first_BatchNormalization_3_2)\n",
    "    \n",
    "    first_SpatialDroupout2D_3 = SpatialDropout2D(dropout_conv)(first_Activation_3_2)\n",
    "    \n",
    "    #conv block 4 for the first three channels\n",
    "    first_Convolution2D_4_1 = Conv2D(fourth_filters, kernel_size, use_bias=False)(first_SpatialDroupout2D_3)\n",
    "    first_BatchNormalization_4_1 = BatchNormalization()(first_Convolution2D_4_1)\n",
    "    \n",
    "    first_Activation_4_1 = Activation('relu')(first_BatchNormalization_4_1)\n",
    "    first_Convolution2D_4_2 = Conv2D(fourth_filters, kernel_size, use_bias=False)(first_Activation_4_1)\n",
    "    \n",
    "    first_BatchNormalization_4_2 = BatchNormalization()(first_Convolution2D_4_2)\n",
    "    first_Activation_4_2 = Activation('relu')(first_BatchNormalization_4_2)\n",
    "    \n",
    "    first_SpatialDroupout2D_4 = SpatialDropout2D(dropout_conv)(first_Activation_4_2)\n",
    "    first_Flatten1 = Flatten()(first_SpatialDroupout2D_4)\n",
    "    \n",
    "    first_Dense_1 = Dense(200, use_bias = False)(first_Flatten1)\n",
    "    print(first_Dense_1.shape)\n",
    "    #first_MaxPool = MaxPooling2D(pool_size)(first_SpatialDroupout2D_4)\n",
    "    \n",
    "    #conv block 1 for the fourth channel\n",
    "    fourth_Convolution2D_1_2 = Conv2D(first_filters, (3,3), use_bias=False)(x_grey)\n",
    "    \n",
    "    fourth_BatchNormalization_1_2 = BatchNormalization()(fourth_Convolution2D_1_2)\n",
    "    fourth_Activation_1_2 = Activation('relu')(fourth_BatchNormalization_1_2)\n",
    "    \n",
    "    fourth_SpatialDroupout2D_1 = SpatialDropout2D(dropout_conv)(fourth_Activation_1_2)\n",
    "    \n",
    "    #conv block 2 for the fourth channel\n",
    "    fourth_Convolution2D_2_1 = Conv2D(second_filters, kernel_size, use_bias=False)(fourth_SpatialDroupout2D_1)\n",
    "    fourth_BatchNormalization_2_1 = BatchNormalization()(fourth_Convolution2D_2_1)\n",
    "    \n",
    "    fourth_Activation_2_1 = Activation('relu')(fourth_BatchNormalization_2_1)\n",
    "    fourth_Convolution2D_2_2 = Conv2D(second_filters, kernel_size, use_bias=False)(fourth_Activation_2_1)\n",
    "    \n",
    "    fourth_BatchNormalization_2_2 = BatchNormalization()(fourth_Convolution2D_2_2)\n",
    "    fourth_Activation_2_2 = Activation('relu')(fourth_BatchNormalization_2_2)\n",
    "    \n",
    "    fourth_SpatialDroupout2D_2 = SpatialDropout2D(dropout_conv)(fourth_Activation_2_2)\n",
    "    \n",
    "    #conv block 3 for the fourth channel\n",
    "    fourth_Convolution2D_3_1 = Conv2D(third_filters, kernel_size, use_bias=False)(fourth_SpatialDroupout2D_2)\n",
    "    fourth_BatchNormalization_3_1 = BatchNormalization()(fourth_Convolution2D_3_1)\n",
    "    \n",
    "    fourth_Activation_3_1 = Activation('relu')(fourth_BatchNormalization_3_1)\n",
    "    fourth_Convolution2D_3_2 = Conv2D(third_filters, kernel_size, use_bias=False)(fourth_Activation_3_1)\n",
    "    \n",
    "    fourth_BatchNormalization_3_2 = BatchNormalization()(fourth_Convolution2D_3_2)\n",
    "    fourth_Activation_3_2 = Activation('relu')(fourth_BatchNormalization_3_2)\n",
    "    \n",
    "    fourth_SpatialDroupout2D_3 = SpatialDropout2D(dropout_conv)(fourth_Activation_3_2)\n",
    "    \n",
    "    #conv block 4 for the fourth channel\n",
    "    fourth_Convolution2D_4_1 = Conv2D(fourth_filters, kernel_size, use_bias=False)(fourth_SpatialDroupout2D_3)\n",
    "    fourth_BatchNormalization_4_1 = BatchNormalization()(fourth_Convolution2D_4_1)\n",
    "    \n",
    "    fourth_Activation_4_1 = Activation('relu')(fourth_BatchNormalization_4_1)\n",
    "    fourth_Convolution2D_4_2 = Conv2D(fourth_filters, kernel_size, use_bias=False)(fourth_Activation_4_1)\n",
    "    \n",
    "    fourth_BatchNormalization_4_2 = BatchNormalization()(fourth_Convolution2D_4_2)\n",
    "    fourth_Activation_4_2 = Activation('relu')(fourth_BatchNormalization_4_2)\n",
    "    \n",
    "    fourth_SpatialDroupout2D_4 = SpatialDropout2D(dropout_conv)(fourth_Activation_4_2)\n",
    "    fourth_Flatten1 = Flatten()(fourth_SpatialDroupout2D_4)\n",
    "    \n",
    "    fourth_Dense_1 = Dense(200, use_bias = False)(fourth_Flatten1)\n",
    "    print(fourth_Dense_1.shape)\n",
    "    #fourth_MaxPool = MaxPooling2D(pool_size)(fourth_SpatialDroupout2D_4)\n",
    "    \n",
    "    concat_layers = tf.keras.layers.concatenate([first_Dense_1,fourth_Dense_1], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #a fully connected (also called dense) layer at the end\n",
    "    Dropout_after_concat = Dropout(dropout_dense)(concat_layers)\n",
    "    Dense_1 = Dense(50, use_bias = False)(Dropout_after_concat)\n",
    "    BatchNormalization_4_1 = BatchNormalization()(Dense_1)\n",
    "    Activation_4_1 = Activation('relu')(BatchNormalization_4_1)\n",
    "    Dropout_1 = Dropout(dropout_dense)(Activation_4_1)\n",
    "    \n",
    "    #Dense_2 = Dense(100, use_bias = False)(Dropout_1)\n",
    "    #BatchNormalization_5_1 = BatchNormalization()(Dense_2)\n",
    "    #Activation_5_1 = Activation('relu')(BatchNormalization_5_1)\n",
    "    #Dropout_2 = Dropout(dropout_dense)(Activation_5_1)\n",
    "    \n",
    "    Dense_2 = Dense(2, activation= 'softmax')(Dropout_1)\n",
    "    \n",
    "    #finally convert to values of 0 to 1 using the sigmoid activation function\n",
    "    return Model([Input_1], [Dense_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch generator to load the data in batches\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=10, dim=(32, 32), n_channels=4,\n",
    "                 n_classes=2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            temp_sample = np.empty((*self.dim, self.n_channels))\n",
    "            temp_sample_greyscale = np.empty((*self.dim, self.n_channels))\n",
    "            \n",
    "            rotate_factor = random.randint(0,3)\n",
    "            \n",
    "            temp_sample_rgb = cv2.imread(os.path.join(INPUT_FOLDER, ID))\n",
    "            temp_sample_rgb = temp_sample_rgb[32:64,32:64,]\n",
    "            \n",
    "            temp_sample_greyscale = cv2.imread(os.path.join(INPUT_FOLDER, ID), cv2.IMREAD_GRAYSCALE)\n",
    "            temp_sample_greyscale = temp_sample_greyscale[32:64,32:64]\n",
    "            \n",
    "            temp_sample_rgb = np.rot90(temp_sample_rgb, rotate_factor)\n",
    "            temp_sample_greyscale = np.rot90(temp_sample_greyscale, rotate_factor)\n",
    "            #zero center each channel\n",
    "            temp_sample[:,:,0] = (temp_sample[:,:,0] - 177.36477546559416)\n",
    "            temp_sample[:,:,1] = (temp_sample[:,:,1] - 138.8431052117129)\n",
    "            temp_sample[:,:,2] = (temp_sample[:,:,2] - 179.00444484090832)\n",
    "            temp_sample[:,:,3] = (temp_sample_greyscale - 155.25222880621973)\n",
    "            \n",
    "            X[i,] = temp_sample\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (2,2)\n",
    "pool_size= (2,2)\n",
    "first_filters = 64\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "fourth_filters = 192\n",
    "\n",
    "#dropout is used for regularization here with a probability of 0.35 for conv layers, 0.5 for the dense layer at the end\n",
    "dropout_conv = 0.35\n",
    "dropout_dense = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_batch_generator = DataGenerator(partition['train'], labels = all_labels, batch_size = 200)\n",
    "my_validation_batch_generator = DataGenerator(partition['validate'], labels = all_labels, batch_size = 157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb_grayscale_split_with_image_roatation_reworked_input\n"
     ]
    }
   ],
   "source": [
    "cnn_name = 'rgb_grayscale_split_with_image_roatation_reworked_input'\n",
    "print(cnn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 3)\n",
      "(?, 200)\n",
      "(?, 200)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 4)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 32, 32, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32, 32, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 30, 30, 64)   1728        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 30, 30, 64)   576         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 30, 30, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 30, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 30, 30, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 30, 30, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 30, 30, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_4 (SpatialDro (None, 30, 30, 64)   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 29, 29, 64)   16384       spatial_dropout2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   16384       spatial_dropout2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 29, 29, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 29, 29, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 64)   16384       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 64)   16384       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 28, 28, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 28, 28, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_5 (SpatialDro (None, 28, 28, 64)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 27, 27, 128)  32768       spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 27, 27, 128)  32768       spatial_dropout2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 27, 27, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 27, 27, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 27, 27, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 27, 27, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 26, 26, 128)  65536       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 26, 26, 128)  65536       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 26, 26, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 26, 26, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 26, 26, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 26, 26, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 26, 26, 128)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_6 (SpatialDro (None, 26, 26, 128)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 192)  98304       spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 192)  98304       spatial_dropout2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 192)  768         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 192)  768         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 192)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 24, 24, 192)  147456      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 24, 24, 192)  147456      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 24, 24, 192)  768         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 24, 24, 192)  768         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 24, 192)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 24, 192)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_3 (SpatialDro (None, 24, 24, 192)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_7 (SpatialDro (None, 24, 24, 192)  0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 110592)       0           spatial_dropout2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 110592)       0           spatial_dropout2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          22118400    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          22118400    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           20000       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 50)           200         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 50)           0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50)           0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            102         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 45,019,726\n",
      "Trainable params: 45,016,298\n",
      "Non-trainable params: 3,428\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\conda\\conda\\envs\\licentav2\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in subtract\n",
      "C:\\Users\\alexa\\AppData\\Local\\conda\\conda\\envs\\licentav2\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in subtract\n",
      "C:\\Users\\alexa\\AppData\\Local\\conda\\conda\\envs\\licentav2\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 184s 368ms/step - loss: 0.5734 - binary_accuracy: 0.7294 - val_loss: 0.8022 - val_binary_accuracy: 0.5953\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 182s 364ms/step - loss: 0.5330 - binary_accuracy: 0.7535 - val_loss: 0.6671 - val_binary_accuracy: 0.6453\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 181s 362ms/step - loss: 0.5235 - binary_accuracy: 0.7579 - val_loss: 0.6436 - val_binary_accuracy: 0.6574\n",
      "Epoch 4/15\n",
      "470/500 [===========================>..] - ETA: 10s - loss: 0.5218 - binary_accuracy: 0.7598"
     ]
    }
   ],
   "source": [
    "TB= TensorBoard(log_dir=OUTPUT_FOLDER_TB +cnn_name)\n",
    "\n",
    "model = get_model(kernel_size, pool_size, first_filters, second_filters, third_filters, fourth_filters, dropout_conv, dropout_dense)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "class_weight = {0: 1.,\n",
    "                1: 1.25\n",
    "    \n",
    "}\n",
    "\n",
    "model.fit_generator(generator=my_training_batch_generator,\n",
    "                                          steps_per_epoch=(500),\n",
    "                                          epochs=15,\n",
    "                                          verbose=1,\n",
    "                                          validation_data=my_validation_batch_generator,\n",
    "                                          validation_steps=(60),\n",
    "                                          callbacks = [TB],\n",
    "                                          class_weight = class_weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.save(OUTPUT_FOLDER + cnn_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
